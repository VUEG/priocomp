```{r setup, echo=FALSE}
library(dplyr)
library(DT)
library(gridExtra) 
library(ggplot2) 
library(ggthemes) 
library(htmlTable)
library(knitr)  
library(readr)
library(scales)  
library(tidyr)
library(viridis)

# Helper functions -------------------------------------------------------

match_method <- Vectorize(
  function(x) {
    if (grepl(".+\\/zonation\\/.+", x)) {
      method <- "ZON"
    } else if (grepl(".+\\/RWR\\/.+", x)) {
      method <- "RWR"
    } else if (grepl(".+\\/ILP\\/.+", x)) {
      method <- "ILP"
    } else {
      stop("Method", x, " not matched")
    }
    return(method)
  }, c("x"), USE.NAMES = FALSE, SIMPLIFY = TRUE)

match_type <- Vectorize(
  function(x) {
    if (grepl("_all.tif", x) | grepl("_all_stats", x) | grepl("02_abf", x)) {
      mtype <- "ALL"
    } else if (grepl("_all_weights.tif", x) | grepl("_all_weights_stats", x) | grepl("wgt", x)) {
      mtype <- "ALL_WGT"
    } else if (grepl("_es", x)) {
      mtype <- "ES"
    } else if (grepl("_bd", x)) {
      mtype <- "BD"
    } else {
      stop("Type ", x, " not matched")
    }
    return(mtype)
  }, c("x"), USE.NAMES = FALSE, SIMPLIFY = TRUE)


# Read in the data -------------------------------------------------------

## Kendall tau rank correlation 

cors <- readr::read_csv("../../analyses/comparison/cross_correlation.csv") %>% 
  mutate(f1_method = match_method(feature1), f1_type = match_type(feature1),
         f2_method = match_method(feature2), f2_type = match_type(feature2),
         key = paste(f1_method, f1_type, f2_method, f2_type, 
                     sep = "_")) %>% 
  select(key, f1_method, f1_type, f2_method, f2_type, tau)

## Map comparison statistic

# NOTE: use the complement of MCS: CMCS = 1 - MCS
mcss <- readr::read_csv("../../analyses/comparison/cross_mcs.csv") %>% 
  mutate(f1_method = match_method(feature1), f1_type = match_type(feature1),
         f2_method = match_method(feature2), f2_type = match_type(feature2),
         key = paste(f1_method, f1_type, f2_method, f2_type, 
                     sep = "_"), cmcs = 1 - mcs) %>% 
  select(key, f1_method, f1_type, f2_method, f2_type, cmcs)

## Jaccard coefficients for different thresholds

jac <- readr::read_csv("../../analyses/comparison/cross_jaccard.csv") %>% 
  mutate(f1_method = match_method(feature1), f1_type = match_type(feature1),
         f2_method = match_method(feature2), f2_type = match_type(feature2),
         key = paste(f1_method, f1_type, f2_method, f2_type, 
                     sep = "_")) %>%
  # Floating point precision issues (e.g. 0.9000000001) caused by NumPy
  mutate(threshold = round(threshold, 2)) %>% 
  filter(threshold == 0.10 | threshold == 0.90) %>%
  select(key, f1_method, f1_type, f2_method, f2_type, threshold, coef) %>% 
  mutate(threshold = paste0("jac_", gsub("\\.", "", threshold))) %>% 
  spread(threshold, coef)

## Join all stats

all <- left_join(cors, mcss, by = c("key" = "key")) %>% 
  select(key, f1_method = f1_method.x, f2_method = f2_method.x, 
         f1_type = f1_type.x, f2_type = f2_type.x, tau, cmcs)
all <- left_join(all, jac, by = c("key" = "key")) %>% 
  select(f1_method = f1_method.x, f1_type = f1_type.x,
         f2_method = f2_method.x, f2_type = f2_type.x, tau, cmcs, jac_01, jac_09)

```

##  Results' interpretation

### Correlation

```{r correlation-1}
# Sort the data along correlation (tau).
all %>% 
  arrange(desc(tau)) %>% 
  filter() %>% 
  datatable() %>% 
  formatRound(columns = c('tau', 'cmcs', 'jac_01', 'jac_09'), digits = 3)
```


## Table 2

```{r table-2}
output <- matrix(paste("Content", LETTERS[1:16]), ncol = 4, byrow = TRUE)

htmlTable(output,
          header = c("ALL", "ALL_WGT", "ES", "BD"),
          rnames = c("ALL", "ALL_WGT", "ES", "BD"),
          rgroup = c("RWR", "ZON", "ILP"),
          
          n.rgroup = c(3, 4),
          cgroup = c("RWR", "ZON", "ILP"),
          n.cgroup = c(3, 4), 
          
          caption = "Basic table with both column spanners (groups) and row groups")

```

